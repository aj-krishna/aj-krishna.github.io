<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ajay Krishna</title>
  
  <meta name="author" content="Ajay Krishna">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Personal website of Ajay Krishna">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/x-icon" href="assets/favicon.ico">

  <script src="js/scramble.js"></script>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-QD31EV6XCR"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-QD31EV6XCR');
  </script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td class="block" style="padding:0%;width:100%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ajay Krishna</name><br>
                <b>Email</b>:
                <font id="email" style="display:inline;">
                  <noscript><i>Please enable Javascript to view</i></noscript>
                </font>
                <script>
                  emailScramble = new scrambledString(document.getElementById('email'),
                    'emailScramble', 'r@gm0kanajiia.cm.yaol7',
                    [3, 13, 14, 15, 11, 1, 4, 5, 7, 8, 2, 17, 9, 6, 20, 22, 19, 10, 16, 21, 18, 12]);
                </script>
              </p>
              <p>
                Namaskara! I am an AI PhD student at Oregon State University advised by <a href="https://web.engr.oregonstate.edu/~sinisa/" target="_blank">Dr. Sinisa Todorovic</a>. My primary research interests are <b>uncertainty estimation and active learning for vision tasks on video data</b>.
              </p>
              <p>
                Previously, I earned a Masters in Computer Science from Oregon State University under the advisement of <a href="https://web.engr.oregonstate.edu/~chenliz/" target="_blank">Dr. Lizhong Chen</a>. My research back then was focused on accelerating and scaling vision models for large scale deployment.
              </p>
              <p style="text-align:center">
                <!-- <a href="">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=baXnNDoAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp|&nbsp
                <a href="https://github.com/ajayosu/" target="_blank">GitHub</a> &nbsp|&nbsp
                <a href="https://www.linkedin.com/in/aj-krishna/" target="_blank">LinkedIn</a>
              </p>
            </td>
            <td class="block" style="padding:0%;width:100%;vertical-align:middle" align="middle">
              <img style="width:140pt" alt="profile photo" src="assets/ajay_krishna.avif" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="border-top: 30px solid white;">
            <td style="padding:0px;width:100%;vertical-align:middle;">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, uncertainty estimation, and active learning. More specifically I am working on active learning schemes that explicitly incorporate the unique constraints of video data. To this end I am working on developing uncertainty estimation techniques tailored to vision tasks on video datasets.
              </p>
              
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;"><tbody>
					
          <tr style="border-bottom:1pt dotted black;">
            <td class="block" style="padding:0px;width:25%;vertical-align:middle" align="middle">
              <img src="assets/pspnet_fig.png" alt="pspnet infer times" width="300pt">
            </td>
            <td class="block" width="75%" valign="middle">
                <papertitle>A Distributed Scheme for Accelerating and Scaling PSPNet</papertitle>
              <br>
              <strong>Ajay Krishna</strong>, Xiang Gu, Andrew Larkin, Perry Hystad, Lizhong Chen
              <br>
              <a href="https://www.american-cse.org/csce2021/conferences-ICAI" target="_blank">
              <em>The  International Conference on Artificial Intelligence, 2021</em> </a>
              <p style="text-align:center"><a href="assets/pspnet_paper.pdf" target="_blank">Paper</a> | <a href="bib/pspnet.bib" target="_blank">Bibtex</a></p>
              <p>Advances in deep learning based image processing techniques have led to their adoption for a wide range of applications,
              and in tow with these developments is a dramatic increase in the availability of high quality datasets. With this comes
              the need to accelerate and scale deep learning applications in order to keep up with the size of data and best use
              available hardware resources. In this paper, we propose a useful scheme to enable accelerated and distributed deployment
              of PSPNet inferences, which allows scaling across disparate compute clusters with recourse for system instability and
              heterogeneity of resources. The systemic incorporation of multiprocessing paradigms and pipelining also allows the
              scheme to mitigate the time penalties of multiscale inference and significantly improves total inference times when used
              on extremely large datasets. The use of this distributed scheme to process close to 150,000 Google Street View images as
              part of a public health study has demonstrated excellent promise in addressing issues of deployment, maintenance, crash
              recovery, and dataset management at scale
              </p>
              
            </td>
          </tr>
          
          </tbody>
          </table>
<!-- 
          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/dreamfusion.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dreamfusion3d.github.io/">
                <papertitle>DreamFusion: Text-to-3D using 2D Diffusion</papertitle>
              </a>
              <br>
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>arXiv</em>, 2022
              <br>
              <a href="https://dreamfusion3d.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
              /
              <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a>
              <p></p>
              <p>
              We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling.
              </p>
            </td>
          </tr> -->


          

        
      </td>
    </tr>
  </table>
  <footer style="width:100%;max-width:800px;margin-right:auto;margin-left:auto;">
    <p style="text-align:right">Credits: <a href="https://jonbarron.info/" target="_blank">Template</a>, <a
        href="https://jeffdonahue.com/" target="_blank">Scrambler</a></p>
  </footer>
</body>

</html>
